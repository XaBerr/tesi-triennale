\lvli{Confronto tra D-Wave e computer classico}

\lvlii{Definizione di quantum speedup}
L'interesse nei quantum computer è legato alla loro capacità di essere molto più veloci dei computer tradizionali a risolvere un determinato tipo di problemi, questa capacità prende il nome di \idx{quantum speedup}; a livello matematico è possibile definirlo\cite{DDQS} come il limite del rapporto
$$S = \lim_{N \to \infty} \frac{C(N)}{Q(N)}$$
tra il tempo $C(N)$ necessario per un computer classico a risolvere un problema di dimensioni $N$ e $Q(N)$ il tempo per un computer quantistico per risolvere lo stesso problema. Questa definizione non richiede la capacità di un quantum computer di ridurre un problema da esponenziale a polinomiale (\idx{speedup esponenziale}) come anticipato nell'introduziome, ma valuta solo la capacità di \textit{scaling} con l'aumentare delle dimensioni della complessità (\idx{speedup polinomiale}).
Per il calcolo di $Q(N)$ sono state fatte delle simulazioni modificando vari parametri nel D-Wave One e nel D-Wave Two e i loro tempi sono stati valutati come $T_{DW}(N) = Q(N)$. Per quanto riguarda i computer classici sono state eseguite delle simulazioni per ogni $C(N)$ le cui prestazioni sono state misurate compensando la componente parallela fisica\cite{EQA} come $\frac{T_{SA-SQA}(N)}{N} \simeq C(N)$.
Da qui è stata definita\cite{DDQS} la relazione:
$$S_{DW} = \lim_{N \to \infty} \frac{T_{SA-SQA}(N)}{N \cdot T_{DW}(N)}$$


\lvlii{Simulazione del computer quantistico attraverso algoritmi classici}
\cite{EQA}Per analizzare il quantum speedup del D-Wave è stato scelto di confrontarlo con due algoritmi classici molto simili SA e SQA nella ricerca del ground state attraverso un modello di Ising a due dimensioni dello spin glass.
Questa scelta è dipesa dalla capacità di essere rimappato in un qualsiasi altro problema np-hard.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.5]{Immagini/correlazione-2-dw.jpg}
  \caption{Correlazione delle prestazione del DW con gli algoritmi classici.}
  \label{figura:correlazione-2-dw}
\end{figure}

I primi esperimenti di comparazione sono stati svolti tramite dei test sulla probabilità di successo $P_{GS}(s) = \frac{M_{GS}}{M}$ nel trovare il ground state. Per ogni dimensione da $N=8$ a $N=108$ sono stati generati $Q=1000$ problemi casuali, e per ogni problema sono state eseguite $M=1000$ istanze di test; i risulati sono stati riportati nella figura \ref{figura:correlazione-2-dw}.
Nel primo grafico (a) è raffigurata la differenza di probabilità di successo tra due configurazioni di parametri impostate sulla stessa macchina della DW per eseguire gli stessi problemi; nel secondo grafico (b) viene confrontata la macchina DW con il SQA mentre nel terzo (c) sempre la macchina DW ma con il SA. Quello che viene messo in mostra è che il comportamento della macchina DW è molto più simile al SQA che al SA deducibile dalla presenza di una distribuzione bimodale, visibile all'estremità della linea rossa rappresentante la perfetta correlazione, sia per il DW che per il SQA ma non presente nel SA.
I $\chi^2$-test hanno sottolineato quello già visibile fornendo i seguenti valori di comparazione $\chi_{DW}^2(s) \approx 1 \cdot M$, $\chi_{SQA}^2(s) \approx 1,25 \cdot M$, $\chi_{SA}^2(s) \geq 2.24 \cdot M$ con:
$$\chi^2(s) = \sum_{i=0}^I \frac{(P_{GS2}(s, i) -P_{GS1}(s, i))^2}{P_{GS1}(s, i)}$$

Ulteriori test sono stati fatti per capire il legame tra SQA e DW. Nel DW sono state svolte delle prove che hanno confermato che il comportamento bimodale aumenta con il diminuire della temperatura, ovvero con l'aumentare dell'effetto quantistico rispetto a quello termico. Per il SQA sono state svolte ulteriori analisi sullo studio della distanza (\idx{gap}) tra il ground state (calcolato mediante \cite{SRVR}) e il primo stato di eccitazione $\Delta E = E_{1} - E_{GS}$ svolgendo in dettaglio due tipologie di problemi o semplici o complessi. È stato ricavato che sia nei problemi semplici che in quelli complessi ci sono due punti critici dove $\Delta E \to 0$, nel punto di inversione di simmetria e per $A/B \to 0$, nessuno di questi influisce nel calcolo. Nei problemi complessi è stato individuato un punto critico aggiuntivo per $A/B \approx 0.5$ che può causare il fallimento dell'annealing dato che a differenza delle altre due si trova nella parte centrale del calcolo come è mostatro in figura \ref{figura:ground-state-gap}.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.38]{Immagini/ground-state-gap.jpg}
  \caption{$\Delta E$ per un problema semplice (\textbf{a}) e per uno complesso (\textbf{b}).}
  \label{figura:ground-state-gap}
\end{figure}

Un'altra osservazione derivante dallo studio dei $\Delta E$ è che problemi semplici presentano distanze di Hamming piccole tra il risultato dell'algoritmo e il ground state più vicino, mentre problemi complessi hanno distanze più grandi.

Combinando tutte queste osservazioni si ottiene la conferma della similitudine tra DW e SQA, infatti il SQA divide i problemi in due categorie: semplici e complessi. Con i problemi complessi contrariamente al SA il SQA riduce i grossi gap in piccole matrici di tunneling aumentando la probabilità di finire in uno stato di bassa energia.

\lvlii{Mancanza di speedup}
\cite{DDQS}Per determinare lo speedup si è deciso quindi di confrontare il DW sia con SQA(PIMC) che con il SA confrontando i valori medi dei tempi in 1000 istanze per risolvere un problema con probabilità $P_p=0.99$.
Per far ciò si sono eseguite $R$ ripetizioni per ogni istanza generando un tempo $t_i = R_i(t_a) \cdot t_a$ dove il numero di ripetizioni è stato calcolato per rispettare la probabilità $P_p$ fissando la media geometrica di successo $\bar{s}(t_a)$ attraverso la formula:
$$R(t_a) = \left\lceil\frac{\ln(1 - P_p)}{\ln(1 - \bar{s}(t_a))}\right\rceil$$

Dal lato delle simulazioni per ottenere $t_a^{SA}, t_a^{SQA}$ si è deciso di contare il numero di MCS e di moltiplicare il valore per il tempo minimo di calcolo.
Per quanto riguarda il DW la procedura è stata più complessa perché partendo dal tempo globale bisognava rimuovere il tempo di setup e ricavarsi quindi il tempo di annealing $t_a^{DW}$.

\begin{wrapfloat}{figure}{I}{0pt}
\includegraphics[width=0.4\textwidth]{Immagini/t_opt.jpg}
\caption{Tempo $t_a^{opt}$ per SQA.}
\label{figura:t_opt}
\end{wrapfloat}

In generale il tempo $t_a$ si è rivelato essere molto delicato dato il legame con altri due parametri: $r$ il valore massimo dei parametri di accoppiamento spaziale tra spin, e $N$ dimensione del problema.
Per il SQA e SA si è scelto di calcolare il tempo ottimo per ogni dimensione del problema ($N$) facendo variare $r$, in questo modo il tempo $t_a^{opt}$ che risulta subottimo per $N$ troppo grandi è stato calcolato in modo tale che risultasse accettabile in base ai test eseguiti come mostrato in esempio in figura \ref{figura:t_opt}. Diversmente è andata per il DW che presentava un valore minimo hardwere $t_a = 20 [\mu s]$ che risulta subottimo per tutti gli $N \le 200$.

Il calcolo dello speedup è stato effettuato attraveso quello del quantile. Per una variabile aleatoria $X$ con densità $p(X)$ e valori $x \in [0, +\infty)$ viene definito \idx{quantile} di parametro $q$ il valore:
$$[X]_q = \int_0^{x_q} p(x) dx$$
Viene quindi definito lo \idx{speedup locale} come \idx{ratio dei quantili}:
$$S_{q}^{RofQ}(N) = \frac{[T_{SA-SQA}(N)]_q}{[T_{DW}(N)]_q}\frac{1}{N}$$
È stato rappresentando graficamente $S_{q}^{RofQ}(N)$ tra DW e SA in figura \ref{figura:RofQ}, visto che per questi test SA è risultato migliore del SQA; non è stata trovata nessuna evidenza di speedup per $N \to \infty$.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.3]{Immagini/RofQ.jpg}
  \caption{RofQ per $r=1$ e $r=7$ tra SA e DW.}
  \label{figura:RofQ}
\end{figure}

Successivamente dagli stessi dati si è provato a cercare uno speedup per un sottoinsieme delle istanze dei problemi generati misurando lo scaling dei quantili del ratio definendo la seguente quantità:
$$S_{q}^{QofR}(N) = \left[\frac{T_{SA-SQA}(N)}{T_{DW}(N)}\right]_q \frac{1}{N}$$
Come si vede da figura \ref{figura:QofR} anche in questo caso non è visibile un particolare speedup.
\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.3]{Immagini/QofR.jpg}
  \caption{QofR per $r=1$ e $r=7$ tra SA e DW.}
  \label{figura:QofR}
\end{figure}


\lvlii{Confronto tra algoritmi classici}
Nonostante il fallimento nel dimostrare lo speedup si è scoperto un altro legame molto interessante, quello tra il SQA(CT-SQA, DT-SQA) e il DW. Tale algoritmo approssima bene il comportamento per $N$ molto piccoli e per $N$ molto grandi\cite{EQA}, in particolare la sua versione continua CT-SQA\cite{QVC}. Infatti confermato dalle basi teoriche, solo il CT-SQA è un vero simulatore per il QA perché le approssimazioni utilizzate per il cambiamento da modello quantistico a classico sono fatte considerando evoluzioni continue del sistema.

\cite{QVC}Un'analisi più approffondita è stata fatta tra SA e SQA dimostrando, contrariamente ai risultati ottenuti negli esperimenti dello speedup, che il SQA diminuisce la sua energia rispetto al ground state (calcolato mediante \cite{SRVR}) molto più velocemente del SA. Nuovi test sono stati eseguiti con tipologia simile ai precedenti, questa volta sono stati generati 1000 problemi casuali con:  $r=3$, $N=80$ e con 1000 istanze ciascuno. Per ogni simulazione è stato calcolato il gap $\Delta E_{res} = E_{final} - E_{GS}$. Per il CT-SQA che è stato usato come simulatore del QA è stata presa $E_{final}$ a caso tra i valori di energia delle fette temporali, mentre per il DT-SQA che è stato utilizzato come algoritmo di ottimizzazione è stata cercata la fetta con energia inferiore.
I risultati sono stati riportati in figura \ref{figura:residua}.
\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.6]{Immagini/residua.jpg}
  \caption{Energie residue nell'esecuzione degli algoritmi.}
  \label{figura:residua}
\end{figure}

\newpage
\lvlii{Conclusioni}
In conclusione il CT-SQA si è rivelato avere prestazioni molto inferiori rispetto al DT-SQA visto che il calcolo usato per ottenere il valore atteso di $E_{final}$ introduce un'energia residua. Questa osservazione potrebbe essere anche il sintomo che il QA non riesca mai a raggiungere le prestazioni del DT-SQA per colpa proprio di energie residue dovute alla continuità e non dall'effetto termico.
Questo al livello fisico si traduce in un problema legato alla capacità di tunneling di trasformare grandi gap in piccoli salti, che avvantaggia il QA nella discesa verso il ground state, ma che introduce uno svantaggio nella ricerca del minimo, infatti diminuendo la distanza dal ground state ai primi stati eccitati, aumenta statisticamente la probabilità di finire in uno di essi.

È possibile che in futuro la D-Wave possa ottimizzare il QA in modo tale che presenti uno speedup rispetto la sua simulazione in un computer classico (CT-SQA) ma che non sia sufficiente a superare le prestazioni del DT-SQA che si è rivelato essere un ottimo algoritmo per i computer tradizionali.

Si augura che con il miglioramento dell'architettura del DW sia possibile confrontare modelli a tre dimensioni o superiori e che possano avere risultati differenti dagli esperimenti realizzati fino ad ora che sono stati eseguiti su un modello di Ising a due dimensioni, con condizioni al contorno periodiche.
